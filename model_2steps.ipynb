{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99597e6b",
   "metadata": {},
   "source": [
    "# 0) Load everything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de53c9eb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39132cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio # for loading MATLAB files\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set() #sets the matplotlib style to seaborn style\n",
    "\n",
    "from scipy.io import loadmat \n",
    "from scipy.ndimage import convolve1d\n",
    "from scipy.signal import butter, filtfilt, iirnotch, sosfiltfilt, welch, resample, hilbert\n",
    "from scipy.stats import mode\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, TimeSeriesSplit \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, recall_score, mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold, SelectPercentile, chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5343903f",
   "metadata": {},
   "source": [
    "## Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01dfb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_npulse_data_path = os.path.join(\"data\", \"npulse\", \"raw\")\n",
    "os.makedirs(raw_npulse_data_path, exist_ok=True)\n",
    "\n",
    "for root, d_names, f_names in os.walk(raw_npulse_data_path):\n",
    "    print('File names:', f_names)\n",
    "\n",
    "list_npulse_data = {}\n",
    "for file in f_names:\n",
    "    print(f\"Loading {file}...\")\n",
    "    raw_data = pd.read_csv(os.path.join(raw_npulse_data_path, file))\n",
    "    list_npulse_data[file] = raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de01d6d8",
   "metadata": {},
   "source": [
    "## Load cleaned data (if existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f810b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "npulse_cleaned_data_path = os.path.join(\"data\", \"npulse\", \"cleaned\")\n",
    "os.makedirs(npulse_cleaned_data_path, exist_ok=True)\n",
    "\n",
    "for root, d_names, f_names in os.walk(npulse_cleaned_data_path):\n",
    "    print('File names:', f_names)\n",
    "\n",
    "list_npulse_cleaned_data = {}\n",
    "for file in f_names:\n",
    "    print(f\"Loading {file}...\")\n",
    "    cleaned_data = pd.read_csv(os.path.join(npulse_cleaned_data_path, file))\n",
    "    list_npulse_cleaned_data[file] = cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf138baa",
   "metadata": {},
   "source": [
    "## Divide data into training and testing (for realism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d6303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into training and testing sets\n",
    "dataset_size = len(list_npulse_cleaned_data)\n",
    "\n",
    "\n",
    "test_size = int(dataset_size * 0.2)  # 20% for testing\n",
    "train_size = dataset_size - test_size  # 80% for training\n",
    "\n",
    "# Take random Files from the list\n",
    "train_files_id = random.sample(list_npulse_cleaned_data.keys(), k=train_size)\n",
    "test_files_id = [key for key in list_npulse_cleaned_data.keys() if key not in train_files_id]\n",
    "\n",
    "print(f\"Train files: {train_files_id}\")\n",
    "print(f\"Test files: {test_files_id}\")\n",
    "\n",
    "# Concatenate the dataframes\n",
    "train_data = pd.concat([list_npulse_cleaned_data[key] for key in train_files_id], ignore_index=True)\n",
    "test_data = pd.concat([list_npulse_cleaned_data[key] for key in test_files_id], ignore_index=True)\n",
    "\n",
    "print(f\"Train data shape: {train_data.head()}\")\n",
    "print(f\"Test data shape: {test_data.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90dbbe7",
   "metadata": {},
   "source": [
    "# 1) Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d1e5b1",
   "metadata": {},
   "source": [
    "categories :\n",
    "- EMG envelope : LP filter on rectified OR RMS on raw\n",
    "- Teager-Kaiser Energy Operator (TKEO) : on raw\n",
    "- Wavelet transform (WT) : on raw\n",
    "- Others : Kalman filter, MCO, MOO, MOOGA, ALED,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dc41e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74febd4e",
   "metadata": {},
   "source": [
    "## Filtering : band-pass filter (20-450Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661aad92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbe5a361",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d3f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "scaler = StandardScaler()\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d4ca7a",
   "metadata": {},
   "source": [
    "# 2) Model 1 : Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd35f9e4",
   "metadata": {},
   "source": [
    "3 categories : \n",
    "- single threshold (ST)\n",
    "- double threshold (DT)\n",
    "- adaptive threshold (AT) : direct on raw emg, using SNR\n",
    "\n",
    "consideration for threshold : \n",
    "- std\n",
    "- period of time\n",
    "- % max voluntary contraction (%MVC)\n",
    "- % max emg amplitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178ed21c",
   "metadata": {},
   "source": [
    "## CWT Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8ae1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mother wavelet (shape of MUAPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2ccbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply CWT to the data\n",
    "def cwt(data, wavelet, scales):\n",
    "    \"\"\"\n",
    "    Perform Continuous Wavelet Transform (CWT) on the data using the specified wavelet and scales.\n",
    "    \n",
    "    Parameters:\n",
    "        data (array-like): Input data to transform.\n",
    "        wavelet (function): Wavelet function to use for the transform.\n",
    "        scales (array-like): Scales at which to compute the CWT.\n",
    "    \n",
    "    Returns:\n",
    "        array: CWT coefficients.\n",
    "    \"\"\"\n",
    "    cwt_coefficients = np.zeros((len(scales), len(data)))\n",
    "    for i, scale in enumerate(scales):\n",
    "        cwt_coefficients[i, :] = wavelet(data, scale)\n",
    "    return cwt_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bdf540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manifestation variable : maximize across scales\n",
    "def max_cwt(cwt_coefficients):\n",
    "    \"\"\"\n",
    "    Compute the maximum CWT coefficients across scales.\n",
    "    \n",
    "    Parameters:\n",
    "        cwt_coefficients (array): CWT coefficients.\n",
    "    \n",
    "    Returns:\n",
    "        array: Maximum CWT coefficients across scales.\n",
    "    \"\"\"\n",
    "    return np.max(cwt_coefficients, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285f4ef7",
   "metadata": {},
   "source": [
    "## Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c3301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold coefficient gamma based on SNR (bias & std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa7e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity detection\n",
    "def detect_activity(data, threshold):\n",
    "    \"\"\"\n",
    "    Detect activity in the data based on a threshold.\n",
    "    \n",
    "    Parameters:\n",
    "        data (array-like): Input data to analyze.\n",
    "        threshold (float): Threshold for activity detection.\n",
    "    \n",
    "    Returns:\n",
    "        array: Boolean array indicating detected activity.\n",
    "    \"\"\"\n",
    "    return np.abs(data) > threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca855386",
   "metadata": {},
   "source": [
    "# 3) Model 2 : Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f297834",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
